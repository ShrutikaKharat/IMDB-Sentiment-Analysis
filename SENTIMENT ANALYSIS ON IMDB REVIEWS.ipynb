{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>For a movie that gets no respect there sure ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bizarre horror movie filled with famous faces ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A solid, if unremarkable film. Matthau, as Ein...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's a strange feeling to sit alone in a theat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You probably all already know this by now, but...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I saw the movie with two grown children. Altho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>You're using the IMDb.  You've given some heft...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This was a good film with a powerful message o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Made after QUARTET was, TRIO continued the qua...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>For a mature man, to admit that he shed a tear...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0  For a movie that gets no respect there sure ar...          0\n",
       "1  Bizarre horror movie filled with famous faces ...          0\n",
       "2  A solid, if unremarkable film. Matthau, as Ein...          0\n",
       "3  It's a strange feeling to sit alone in a theat...          0\n",
       "4  You probably all already know this by now, but...          0\n",
       "5  I saw the movie with two grown children. Altho...          0\n",
       "6  You're using the IMDb.  You've given some heft...          0\n",
       "7  This was a good film with a powerful message o...          0\n",
       "8  Made after QUARTET was, TRIO continued the qua...          0\n",
       "9  For a mature man, to admit that he shed a tear...          0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/train.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wow, I forgot how great this movie was until I stumbled upon it while looking through the garage. It\\'s a kind of strange combination of a bio of Michael Jackson, a collection of musical vignettes, and a story about a super hero fighting to save some little kids. The vignettes are good (especially Speed Demon), but the best part of this movie is the super hero segment, in which Michael Jackson turns into a car, a robot, and finally a spaceship (and it\\'s just as weird as it sounds). Joe Pesci is hilarious, and has enough cool imagery and great music to entertain throughout!  The real gem however is the incredible \"Smooth Criminal\" video, which makes the movie worth owning for that part alone!'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'][200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'][4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'][17000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Transforming documents into Feature Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count =  CountVectorizer()\n",
    "docs = np.array(['Im not looking for somebody',\n",
    "                 'With some superhuman gifts',\n",
    "                 'Some superhero',\n",
    "                 'Some fairytale bliss',\n",
    "                 'Just something I can turn to',\n",
    "                 'Somebody I can kiss',\n",
    "                 'I want something just like this'])\n",
    "bag = count.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'im': 5, 'not': 10, 'looking': 9, 'for': 3, 'somebody': 12, 'with': 20, 'some': 11, 'superhuman': 15, 'gifts': 4, 'superhero': 14, 'fairytale': 2, 'bliss': 0, 'just': 6, 'something': 13, 'can': 1, 'turn': 18, 'to': 17, 'kiss': 7, 'want': 19, 'like': 8, 'this': 16}\n"
     ]
    }
   ],
   "source": [
    "print(count.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0]\n",
      " [0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(bag.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Word Relevancy using term-frequency(tf) and inverse document-frequency(idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   0.   0.   0.46 0.   0.46 0.   0.   0.   0.46 0.46 0.   0.38 0.\n",
      "  0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.53 0.   0.   0.   0.   0.   0.   0.38 0.   0.\n",
      "  0.   0.53 0.   0.   0.   0.   0.53]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.58 0.   0.\n",
      "  0.82 0.   0.   0.   0.   0.   0.  ]\n",
      " [0.63 0.   0.63 0.   0.   0.   0.   0.   0.   0.   0.   0.45 0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.41 0.   0.   0.   0.   0.41 0.   0.   0.   0.   0.   0.   0.41\n",
      "  0.   0.   0.   0.5  0.5  0.   0.  ]\n",
      " [0.   0.54 0.   0.   0.   0.   0.   0.65 0.   0.   0.   0.   0.54 0.\n",
      "  0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.4  0.   0.48 0.   0.   0.   0.   0.4\n",
      "  0.   0.   0.48 0.   0.   0.48 0.  ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "np.set_printoptions(precision =2)\n",
    "tfidf = TfidfTransformer(use_idf=True, norm='l2', smooth_idf=True)\n",
    "print(tfidf.fit_transform(bag).toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'h for Alan \"The Skipper\" Hale jr. as a police Sgt.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0,'text'][-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocessor(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',text)\n",
    "    text = re.sub('[\\W]+', ' ',text.lower()) +\\\n",
    "    ' '.join(emoticons).replace('-','')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'h for alan the skipper hale jr as a police sgt '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor(df.loc[0,'text'][-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is a test :) :( :)'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor(\"</a>This :) is a :( test :-)! \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for a movie that gets no respect there sure are a lot of memorable quotes listed for this gem imagine a movie where joe piscopo is actually funny maureen stapleton is a scene stealer the moroni character is an absolute scream watch for alan the skipper hale jr as a police sgt '"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one of the great mysteries of life suffered from daily is why nice girls so often are more interested in the jerks and heels than in the nice guys worse when the nice guys even want to marry those girls the girls still prefer the jerks and heels even after the jerks and heels have shown their contempt have shown they re just interested in using the girls stu erwin is the nice guy who continues to be nice after being lied to and cheated and even after losing the girl completely clark gable is the jerk and he is perfect in the role rather a sad note to his fans jean harlow comes across as a more slender mae west even sounding like la west in some of her cynical throwaway lines somewhat puzzling is that so many of the other characters intended to be bad guys i mean heck they re locked up so they must be are so obviously nice people in fact there are lots of nice people here people who in a lesser film or story would be snarling and back stabbing but here go out of their way to help someone else so maybe the story is rather clich√©d at least by modern standards but ultimately the viewer will be glad to have watched the biggest complaint i have is that so many really good actors are not given credit once again we can say a fervent thank you to imdb com '"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][3000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  5.Tokenization of Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_porter(text):\n",
    "    return [porter.stem(word) for word in text.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['runners', 'like', 'running', 'and', 'thus', 'they', 'run']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('runners like running and thus they run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['runner', 'like', 'run', 'and', 'thu', 'they', 'run']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_porter('runners like running and thus they run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/shrutika/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['runner', 'like', 'run', 'thu', 'run', 'lot']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "[w for w in tokenizer_porter('a runner likes the running and thus he runs a lot')[-10:]if w not in stop]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.Transform Text data into TF-IDF vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(strip_accents = None,\n",
    "                        lowercase = False,\n",
    "                        preprocessor = None,\n",
    "                        tokenizer = tokenizer_porter,\n",
    "                        use_idf = True,\n",
    "                        norm = 'l2',\n",
    "                        smooth_idf = True)\n",
    "y = df.sentiment.values\n",
    "X = tfidf.fit_transform(df.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Document Classification using Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.5, shuffle = True, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  1.1min remaining:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.4min finished\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "classifier = LogisticRegressionCV(cv=5, \n",
    "                                  scoring='accuracy',\n",
    "                                  random_state=0,\n",
    "                                  n_jobs=-1,\n",
    "                                  verbose=3,\n",
    "                                  max_iter=300).fit(X_train,y_train)\n",
    "saved_model = open('saved_model.sav', 'wb')\n",
    "pickle.dump(classifier,saved_model)\n",
    "saved_model.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "24995    1\n",
       "24996    1\n",
       "24997    1\n",
       "24998    1\n",
       "24999    1\n",
       "Name: sentiment, Length: 25000, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Model Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'saved_model.sav'\n",
    "saved_classifier = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88664"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_classifier.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
